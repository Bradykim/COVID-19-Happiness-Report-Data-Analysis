# -*- coding: utf-8 -*-
"""Projectv2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/104yzTlX5QVsor6OWd7MPfBwPlU4Xl3ph

# Final Project

This project aims to discover the relationship between data from the World Happiness Report and the World Health Organization (WHO) COVID-19 data through statistical analysis and inference with the utilities provided by Python's extensive resources and libraries.

# Importing, Cleaning, & Merging
"""

#Importing 
import pandas as pd
import numpy as np
import seaborn as sns
from scipy import stats

#Downloading Files
from google.colab import auth
auth.authenticate_user()

from pydrive.drive import GoogleDrive
from pydrive.auth import GoogleAuth
from oauth2client.client import GoogleCredentials
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

#Opening happiness report csv
myfile = drive.CreateFile({'id': '1165QOPLrZHMOVquWKY4p3z3ATv4llPBh'})
myfile.GetContentFile('happiness.csv')

#Opening Covid csv
mycovid = drive.CreateFile({'id': '118u-1owmdBK0GOp-n86zafuZrk0wXzpP'})
mycovid.GetContentFile('coviddata.csv')

#Opening json for heatmap
myheatmap = drive.CreateFile({'id':"1F1vUStd3XMGhb71j3jXgRArZGt_HigeF"})
myheatmap.GetContentFile('custom.geo.json')

#Reading World Happiness File
#Selecting the happiness data from 2019 since we are looking at the relationship to Covid cases
happiness = pd.read_csv("happiness.csv")
happiness_2019 = happiness[happiness["year"] == 2019]
happiness_2019 = happiness_2019.set_index("Country name")
happiness_2019.head(10)

#Reading COVID File
covid = pd.read_csv("coviddata.csv")
covidSorted = covid.sort_values(by = "Name", ascending= True)
covidSorted.head(10)

#Merging
new_merge = pd.merge(covidSorted, happiness_2019, left_on="Name", right_index=True)
new_merge.head(10)

"""# Visualization"""

# Life Ladder
sns.relplot(x = "Life Ladder", y="Cases - cumulative total per 100000 population", data= new_merge).set(title = "Life Ladder in Comparision to Cases - cumulative total per 100000 population")

# Log GDP per capita
sns.relplot(x = "Log GDP per capita", y="Cases - cumulative total per 100000 population", data= new_merge).set(title = "Log GDP per capita in Comparision to Cases - cumulative total per 100000 population")

# Social support
sns.relplot(x = "Social support", y="Cases - cumulative total per 100000 population", data= new_merge).set(title = "Social support in Comparision to Cases - cumulative total per 100000 population")

# Healthy life expectancy at birth
sns.relplot(x = "Healthy life expectancy at birth", y="Cases - cumulative total per 100000 population", data= new_merge).set(title = "Healthy life expectancy at birth in Comparision to Cases - cumulative total per 100000 population")

# Freedom to make life choices
sns.relplot(x="Freedom to make life choices", y="Cases - cumulative total per 100000 population", data=new_merge).set(title = "Freedom to make life choices in Comparision to Cases - cumulative total per 100000 population")

#Generosity
sns.relplot(x="Generosity", y="Cases - cumulative total per 100000 population", data=new_merge).set(title = "Generosity in Comparision to Cases - cumulative total per 100000 population")

#Perceptions of corruption
sns.relplot(x="Perceptions of corruption", y="Cases - cumulative total per 100000 population", data=new_merge).set(title = "Perceptions of corruptions in Comparision to Cases - cumulative total per 100000 population")

#Positive affect
sns.relplot(x="Positive affect", y="Cases - cumulative total per 100000 population", data=new_merge).set(title = "Positive affect in Comparision to Cases - cumulative total per 100000 population")

#Negative Affect
sns.relplot(x="Negative affect", y="Cases - cumulative total per 100000 population", data=new_merge).set(title = "Negative affect in Comparision to Cases - cumulative total per 100000 population")

"""# Hypothesis Test"""

# Median GDP
gdp_med = new_merge["Log GDP per capita"].median()
print("Median Log GDP per capita:",gdp_med)

# Data Prep for Hypothesis Test
above = new_merge[new_merge["Log GDP per capita"] > gdp_med]
below = new_merge[new_merge["Log GDP per capita"] < gdp_med]

ab_mean = above["Cases - cumulative total per 100000 population"].mean()
ab_std = above["Cases - cumulative total per 100000 population"].std()
ab_n = above.shape[0]
print((ab_mean, ab_std, ab_n))

be_mean = below["Cases - cumulative total per 100000 population"].mean()
be_std = below["Cases - cumulative total per 100000 population"].std()
be_n = below.shape[0]
print((be_mean, be_std, be_n))

# Hypothesis Test of Two Means
p_value = stats.ttest_ind_from_stats(mean1 = ab_mean, std1 = ab_std , nobs1 = ab_n,
                                 mean2 = be_mean, std2 = be_std, nobs2 = be_n)[1] 
print("P Value:", p_value / 2)

"""#### Test Type: One-Sided Test

#### Hypotheses 
    $H_0$ = Countries with `Log GDP per capita` below the median have the same average `Cases - cumulative total per 100000 population` as countries with `Log GDP per capita` above the median
    
    $H_A$ = Countries with `Log GDP per capita` below the median have lower average `Cases - cumulative total per 100000 population` than countries with `Log GDP per capita` above the median
    
#### Interpretation
From this test, we can conclude that countries with `Log GDP per capita` below the median have lower average `Cases - cumulative total 100000 population` than countries with `Log GDP per capita` above the median because the p-value is much less that 0.05 which indicates that the null hypothesis can be rejected.

# Prediction Model
"""

#Variables Used for Prediction Model based off of Correlation

#Correlation Calculation 
corr = new_merge.corr()
corr = corr.loc["Life Ladder" : "Negative affect"]
corr = corr["Cases - cumulative total per 100000 population"]
corr = corr.sort_values(ascending = True)
print(corr)

#Drop NaN values for prediction model to work
drop_merge = new_merge.dropna()

#Import necessary libraries for prediction model
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

#Data of the happiness variables with the highest correlation
data = drop_merge[["Life Ladder", "Social support", "Healthy life expectancy at birth", "Log GDP per capita"]].values
#Target is Covid cases 
target = drop_merge["Cases - cumulative total per 100000 population"].values
#Build linear regression model
linear_model = LinearRegression()
linear_model.fit(X=data, y=target)
drop_merge["prediction"] = linear_model.predict(data)
#Calculation of holistic variables of the prediction model
mse = mean_squared_error(drop_merge["Cases - cumulative total per 100000 population"].values,drop_merge["prediction"].values) # float: MSE
r2 = r2_score(drop_merge["Cases - cumulative total per 100000 population"].values,drop_merge["prediction"].values) # float: R^2 score

...

# Leave this line here to print the result
print("MSE:", mse, "r^2:", r2)

"""# Additional Analysis (Global Heatmap/Chloropeth Map)"""

#Creating dataframes for heatmap visualization
covid_heatmap = new_merge[["Name", "Cases - cumulative total per 100000 population"]]
records = covid_heatmap.to_records(index = False)
covid_heatmap = list(records)
covid_heatmap[-6][0]= 'United States of America'
print (covid_heatmap[:5])

# Utilize google maps and functions provided by a github
from google.colab import output
output.enable_custom_widget_manager()

from google.colab import output
output.disable_custom_widget_manager()

!pip install gmaps
!pip install gmaps.datasets
!pip install gmaps.geojson_geometries

import gmaps
import gmaps.geojson_geometries
gmaps.configure(api_key='AIzaSyCpc1HUbAwT-sumTzk6XHJtVEJVV7eeYsM')

countries_geojson = gmaps.geojson_geometries.load_geometry('countries')

fig = gmaps.figure()

covid_layer = gmaps.geojson_layer(countries_geojson)
fig.add_layer(covid_layer)

rows = covid_heatmap # 'rows' is a list of tuples
country2covid = dict(rows)

fig



from matplotlib.cm import viridis
from matplotlib.colors import to_hex

# We will need to scale the COVID values to lie between 0 and 1
min_covid = min(country2covid.values())
max_covid = max(country2covid.values())
covid_range = max_covid - min_covid

def calculate_color(covid):
    """
    Convert the covid coefficient to a color
    """
    # make covid a number between 0 and 1
    normalized_covid = (covid - min_covid) / covid_range

    # invert covid so that high inequality gives dark color
    inverse_covid = 1.0 - normalized_covid

    # transform the covid coefficient to a matplotlib color
    mpl_color = viridis(inverse_covid)

    # transform from a matplotlib color to a valid CSS color
    gmaps_color = to_hex(mpl_color, keep_alpha=False)

    return gmaps_color
colors = []
for feature in countries_geojson['features']:
    country_name = feature['properties']['name']
    try:
        covid = country2covid[country_name]
        color = calculate_color(covid)
    except KeyError:
        # no covid for that country: return default color
        color = (0, 0, 0, 0.3)
    colors.append(color)
fig = gmaps.figure()
covid_layer = gmaps.geojson_layer(
    countries_geojson,
    fill_color=colors,
    stroke_color=colors,
    fill_opacity=0.8)
fig.add_layer(covid_layer)
fig



#Heatmap code 2
import json

with open('custom.geo.json') as f:
    geo_world = json.load(f)

found = []
missing = []
countries_geo = []
conv_dict = {'Bosnia and Herz.': 'Bosnia and Herzegovina',
    "CÃ´te d'Ivoire": "Ivory Coast",
    'Dominican Rep.':'Dominican Republic',
    'Lao PDR':'Laos',
    'Palestine':'Palestinian Territories'}

tmp = new_merge.set_index('Name')

for country in geo_world['features']:
    # Country name detection
    country_name = country['properties']['name']
    # Replace for mismatched names
    country_name = conv_dict[country_name] if country_name in conv_dict.keys() else country_name
    go_on = country_name in tmp.index
    # If country is in original dataset or transition dictionnary
    if go_on:
        found.append(country_name)
        geometry = country['geometry']
        countries_geo.append({
            'type': 'Feature',
            'geometry': geometry,
            'id':country_name
        })
    else:
        missing.append(country_name)

print(f'Countries found    : {len(found)}')
print(f'Countries not found: {len(missing)}')
geo_world_ok = {'type': 'FeatureCollection', 'features': countries_geo}

pip install -U plotly

#Prepping data for heatmap
new_merge['count_color'] = new_merge["Cases - cumulative total per 100000 population"].apply(np.log10)

max_log = new_merge['count_color'].max()
max_val = int(max_log) + 1

# Prepping colorbar
values = [i for i in range(max_val)]
ticks = [10**i for i in values]

import plotly.express as px
#Making heatmap
fig = px.choropleth_mapbox(
    new_merge,
    geojson=geo_world_ok,
    locations='Name',
    color=new_merge['count_color'],
    color_continuous_scale='YlOrRd',
    range_color=(0, new_merge['count_color'].max()),
    mapbox_style='open-street-map',
    zoom=1,
    opacity=0.6
)

fig.update_layout(
    margin={'r':0,'t':0,'l':0,'b':0},
    coloraxis_colorbar={
        'title':'Cases - Cumulative Total per 100000 Population (Log Scale)',
        'tickvals':values,
        'ticktext':ticks        
    }
)

fig.show()

#GDP choropleth
max_log = new_merge['Log GDP per capita'].max()
max_val = int(max_log) + 1

# Prepping colorbar
values = [i for i in range(max_val)]
ticks = [10**i for i in values]

#Making heatmap
fig = px.choropleth_mapbox(
    new_merge,
    geojson=geo_world_ok,
    locations='Name',
    color=new_merge['Log GDP per capita'],
    color_continuous_scale='YlOrRd',
    range_color=(0, new_merge['Log GDP per capita'].max()),
    mapbox_style='open-street-map',
    zoom=1,
    opacity=0.6
)

fig.update_layout(
    margin={'r':0,'t':0,'l':0,'b':0},
    coloraxis_colorbar={
        'title':'Log GDP per Capita',
        'tickvals':values,
        'ticktext':ticks        
    }
)

fig.show()

new_merge["Log GDP per capita"].min()

